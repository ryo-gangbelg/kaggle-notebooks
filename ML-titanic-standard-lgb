#numpyとpandasをimport
import numpy as np
import pandas as pd

#datasetをimport
train_df = pd.read_csv("../input/titanic/train.csv")
test_df = pd.read_csv("../input/titanic/test.csv")
submission = pd.read_csv("../input/titanic/gender_submission.csv")

#データ数の確認
print(train_df.shape)
print(test_df.shape)
print(submission.shape)

#データの型の確認
train_df.dtypes

#データの概要を確認
train_df.describe()

#各特徴量の分析

train_df["Sex"].value_counts()
train_df["Embarked"].value_counts()
train_df["Cabin"].value_counts()

#欠損値確認
train_df.isnull().sum()
test_df.isnull().sum()

%matplotlib inline
import matplotlib.pyplot as plt
import seaborn as sns
plt.style.use("ggplot")

train_df_dropEmNa = train_df[["Embarked", "Survived", "PassengerId"]].dropna()
train_df_dropEmNa.groupby(["Embarked","Survived"]).count()

embarked_df = train_df_dropEmNa.groupby(["Embarked","Survived"]).count().unstack()

#matplotlibで可視化
embarked_df.plot.bar(stacked=False)

sex_df = train_df[["Sex", "Survived", "PassengerId"]].dropna().groupby(["Sex", "Survived"]).count().unstack()
sex_df.plot.bar(stacked=False)

plt.hist(train_df[train_df["Survived"] == 0][["Age"]].values, 
         histtype="barstacked", bins=8, label = ("Death"))
plt.legend()

plt.hist(train_df[train_df["Survived"] == 1][["Age"]].values, 
         histtype="barstacked", bins=8, label = ("Survived"))
plt.legend()

#カテゴリ変数をダミー変数化
train_df_corr = pd.get_dummies(train_df,
                              columns = ["Sex"],
                              drop_first=True)
train_df_corr.head(20)

train_df_corr = pd.get_dummies(train_df_corr,
                              columns = ["Embarked"],
                              drop_first = False)
train_df_corr.head(20)

#相関行列の作成
train_corr = train_df_corr.corr()
train_corr

plt.figure(figsize=(9,9))
sns.heatmap(train_corr * 100, vmax=100, vmin=-100, center=0,
           annot = True)

all_df = pd.concat([train_df, test_df], sort = False).reset_index(drop = True)

Fare_mean = all_df[["Pclass", "Fare"]].groupby("Pclass").mean().reset_index()
Fare_mean.columns = ["Pclass", "Fare_mean"]
all_df = pd.merge(all_df, Fare_mean, on="Pclass", how="left")
all_df.loc[(all_df["Fare"].isnull()), "Fare"] = all_df["Fare_mean"]
all_df = all_df.drop("Fare_mean", axis = 1)

all_df["Name"].head(20)
name_df = all_df["Name"].str.split("[,.]", 2, expand=True)
name_df.columns = ["family_name", "honorific", "name"]
name_df["family_name"] = name_df["family_name"].str.strip()
name_df["honorific"] = name_df["honorific"].str.strip()
name_df["name"] = name_df["name"].str.strip()
name_df["honorific"].value_counts()
all_df = pd.concat([all_df, name_df], axis = 1)

plt.figure(figsize=(18, 5))
sns.boxplot(x="honorific", y="Age", data=all_df)

all_df[["Age", "honorific"]].groupby("honorific").mean()

train_df = pd.concat([train_df, name_df[0: len(train_df)].reset_index(drop=True)], axis = 1)
test_df = pd.concat([test_df, name_df[len(train_df):].reset_index(drop=True)], axis = 1)

honorific_df = train_df[["honorific", "Survived", "PassengerId"]].dropna().groupby(["honorific", "Survived"]).count().unstack()
honorific_df.plot.bar(stacked=True)

#reset_index()としないとhonorificがindex化されてしまう
honorific_age_mean = all_df[["honorific", "Age"]].groupby("honorific").mean().reset_index()
honorific_age_mean.columns = ["honorific", "honorific_age"]
all_df = pd.merge(all_df, honorific_age_mean, on ="honorific", how = "left")
all_df.loc[(all_df["Age"].isnull()), "Age"] = all_df["honorific_age"]
all_df = all_df.drop(["honorific_age"], axis = 1)

all_df["family_num"] = all_df["Parch"] + all_df["SibSp"]
all_df["family_num"].value_counts()

all_df.loc[all_df["family_num"] == 0, "alone"] = 1
all_df["alone"].fillna(0, inplace=True)

all_df = all_df.drop(["PassengerId", "Name", "family_name", "name", "Ticket", "Cabin"], axis = 1)

categories = all_df.columns[all_df.dtypes == "object"]
print(categories)

all_df.loc[~((all_df["honorific"]=="Mr") | (all_df["honorific"] == "Miss") | (all_df["honorific"]=="Mrs") | (all_df["honorific"]=="Master")), "honorific"] = "other"
all_df.head(50)

from sklearn.preprocessing import LabelEncoder

all_df["Embarked"].fillna("missing", inplace=True)
all_df.isnull().sum()

le = LabelEncoder()
le = le.fit(all_df["Sex"])
EncodedSex = le.transform(all_df["Sex"])
all_df["Sex"] = EncodedSex

for cat in categories:
    le = LabelEncoder()
    print(cat)
    if all_df[cat].dtypes == "object":
        le = le.fit(all_df[cat])
        all_df[cat] = le.transform(all_df[cat])

train_df = all_df[~all_df["Survived"].isnull()]
test_df = all_df[all_df["Survived"].isnull()]

train_X = train_df.drop("Survived", axis=1)
train_Y = train_df["Survived"]

test_X = test_df.drop("Survived", axis = 1).reset_index(drop=True)

import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
X_train, X_valid, y_train, y_valid = train_test_split(train_X, train_Y, test_size=0.2)
categories = ["Embarked", "Pclass", "Sex", "honorific", "alone"]
lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=categories)
lgb_eval = lgb.Dataset(X_valid, y_valid, categorical_feature=categories, reference=lgb_train)
lgbm_params = {
    "objective":"binary",
    "random_seed":1234
}
model_lgb = lgb.train(lgbm_params,
                     lgb_train,
                     valid_sets=lgb_eval,
                     num_boost_round=100,
                     early_stopping_rounds=20,
                     verbose_eval=10)

model_lgb.feature_importance()
importance = pd.DataFrame(model_lgb.feature_importance(), index = X_train.columns, columns=["importance"]).sort_values(by="importance", ascending=True)
importance.plot.barh()

y_pred = model_lgb.predict(X_valid, num_iteration=model_lgb.best_iteration)
from sklearn.metrics import accuracy_score
accuracy_score(y_valid, np.round(y_pred))
#0.8547486033519553
pred = model_lgb.predict(test_X)

preds_int = (pred > 0.5).astype(int)
submission["Survived"] = preds_int

submission.to_csv("titanic_submit01.csv", index=False)







